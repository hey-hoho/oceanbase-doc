# 使用 OBD 进行集群的扩容

本文将通过示例介绍如何借助 OBD 把 1-1-1 的集群扩容成 2-2-2 的集群。

## 前提条件

本文以原集群名为 test1，新集群名为 test2 为例进行介绍。本次示例操作共用到 6 台机器，其中三台机器用来组成原集群，IP 分别为 10.10.10.1/2/3；另外三台机器准备新加入集群，用来扩容，IP 分别为 10.10.10.4/5/6。

您在执行下文步骤前需确定已经部署了一个 1-1-1 的集群，集群配置示例如下，配置文件中各配置项介绍可参见 OBD 文档 [配置文件说明](https://www.oceanbase.com/docs/community-obd-cn-1000000000197040)。

```yaml
#Only need to configure when remote login is required
user:
  username: admin
  # password:
  key_file: /home/admin/.ssh/id_rsa
#   port: your ssh port, default 22
#   timeout: ssh connection timeout (second), default 30
oceanbase-ce:
  servers:
    - name: z1
      # Please don't use hostname, only IP can be supported
      ip: 10.10.10.1
    - name: z2
      ip: 10.10.10.2
    - name: z3
      ip: 10.10.10.3
  global:
    devname: eth0
    cluster_id: 1
    memory_limit: 8G # The maximum running memory for an observer
    system_memory: 4G # The reserved system memory. system_memory is reserved for general tenants. The default value is 30G.
    ......  # 省略部分配置项
    root_password: ********  # root user password, can be empty
    proxyro_password: ******** # proxyro user pasword, consistent with obproxy's observer_sys_password, can be empty
  z1:
    mysql_port: 2881 # External port for OceanBase Database. The default value is 2881.
    rpc_port: 2882 # Internal port for OceanBase Database. The default value is 2882.
    home_path: /home/admin/oceanbase/test1
    data_dir: /data/test1
    redo_dir: /redo/test1
    zone: zone1
  z2:
    mysql_port: 2881 # External port for OceanBase Database. The default value is 2881.
    rpc_port: 2882 # Internal port for OceanBase Database. The default value is 2882.
    home_path: /home/admin/oceanbase/test1
    data_dir: /data/obredo_dir: /redo/test1
    zone: zone2
  z3:
    mysql_port: 2881 # External port for OceanBase Database. The default value is 2881.
    rpc_port: 2882 # Internal port for OceanBase Database. The default value is 2882.
    home_path: /home/admin/oceanbase/test1
    data_dir: /data/test1
    redo_dir: /redo/test1
    zone: zone3
obproxy-ce:
  depends:
    - oceanbase-ce
  servers:
    - 10.10.10.1
  global:
    listen_port: 2883 # External port. The default value is 2883.
    prometheus_listen_port: 2884 # The Prometheus port. The default value is 2884.
    home_path: /home/admin/obproxy
    rs_list: 10.10.10.1:2881;10.10.10.2:2881;10.10.10.3:2881
    enable_cluster_checkout: false
    cluster_name: obcluster
    obproxy_sys_password: ******** # obproxy sys user password, can be empty
    observer_sys_password: ******** # proxyro user pasword, consistent with oceanbase-ce's proxyro_password, can be empty
```

## 查看集群信息

1. 创建一个普通租户 ob_test1

   ```bash
   obd cluster tenant create test1 -n ob_test1 -s 'ob_tcp_invited_nodes="%"'
   ```

   > **说明**
   >
   > * 这里以集群名是 `test1`，租户名是 `ob_test1` 为例，您需根据实际情况填写集群名，并为租户命名。
   >
   > * 该步骤是为 **集群扩容** 第 6 步业务租户扩容所准备。

2. 使用 root 用户登录集群的 sys 租户，查看租户是否创建成功

   ```sql
   SELECT * FROM oceanbase.gv$tenant;
   ```

   通过返回结果可看到所创建的租户，则表示创建成功。

3. 查看机器列表

   ```sql
   select svr_ip,id,zone,status from __all_server;
   ```

   通过返回结果可看到此集群中有 3 台机器。

## 集群扩容

1. 写一份新的配置文件，并通过 OBD 进行部署

   ```bash
   obd cluster deploy test2 -c test2.yaml
   ```

   这里的 `test2` 是部署集群名称，并不固定，您可根据实际情况命名，不能和已存在的集群名重复（可执行 `obd cluster list` 命令查看现有集群名）。新集群的配置文件示例如下，配置文件中各配置项介绍可参见 OBD 文档 [配置文件说明](https://www.oceanbase.com/docs/community-obd-cn-1000000000197040)。

   ```yaml
   #Only need to configure when remote login is required
   user:
     username: admin
     # password:
     key_file: /home/admin/.ssh/id_rsa
   #   port: your ssh port, default 22
   #   timeout: ssh connection timeout (second), default 30
   oceanbase-ce:
     servers:
       - name: z4
         # Please don't use hostname, only IP can be supported
         ip: 10.10.10.4
       - name: z5
         ip: 10.10.10.5
       - name: z6
         ip: 10.10.10.6
     global:
       devname: eth0
       cluster_id: 1
       memory_limit: 8G # The maximum running memory for an observer
       system_memory: 4G # The reserved system memory. system_memory is reserved for general tenants. The default value is 30G.
       ......  # 省略部分配置项
       root_password: ******** # root user password, can be empty
       proxyro_password: ******** # proxyro user pasword, consistent with obproxy's observer_sys_password, can be empty
     z4:
       mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
       rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
       home_path: /home/admin/oceanbase/test2
       data_dir: /data/test2
       redo_dir: /redo/test2
       zone: zone1
     z5:
       mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
       rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
       home_path: /home/admin/oceanbase/test2
       data_dir: /data/test2
       redo_dir: /redo/otest2
       zone: zone2
     z6:
       mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
       rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
       home_path: /home/admin/oceanbase/test2
       data_dir: /data/test2
       redo_dir: /redo/test2
       zone: zone3
   ```

2. 把新集群的配置文件复制一份到原集群配置文件中

   1. 查看配置路径

      ```bash
      obd cluster list
      ```

   2. 打开原集群配置文件，将新集群配置文件的内容复制到原集群配置文件中

      ```bash
      vim .obd/cluster/test1/config.yaml
      ```

      修改原集群配置文件前建议先备份原集群的配置文件，以防操作过程中出现未预期的问题。新配置文件的内容需放在原本配置文件对应内容之后，修改后的配置文件示例如下。

      ```yaml
      #Only need to configure when remote login is required
      user:
        username: admin
        # password:
        key_file: /home/admin/.ssh/id_rsa
      #   port: your ssh port, default 22
      #   timeout: ssh connection timeout (second), default 30
      oceanbase-ce:
        servers:
          - name: z1
            # Please don't use hostname, only IP can be supported
            ip: 10.10.10.1
          - name: z2
            ip: 10.10.10.2
          - name: z3
            ip: 10.10.10.3
          - name: z4
            # Please don't use hostname, only IP can be supported
            ip: 10.10.10.4
          - name: z5
            ip: 10.10.10.5
          - name: z6
            ip: 10.10.10.6
        global:
          devname: eth0
          cluster_id: 1
          memory_limit: 8G # The maximum running memory for an observer
          system_memory: 4G # The reserved system memory. system_memory is reserved for general tenants. The default value is 30G.
          ......  # 省略部分配置项
          root_password: ******** # root user password, can be empty
          proxyro_password: ******** # proxyro user pasword, consistent with obproxy's observer_sys_password, can be empty
        z1:
          mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
          rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
          home_path: /home/admin/oceanbase/test1
          data_dir: /data/test1
          redo_dir: /redo/test1
          zone: zone1
        z2:
          mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
          rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
          home_path: /home/admin/oceanbase/test1
          data_dir: /data/test1
          redo_dir: /redo/test1
          zone: zone2
        z3:
          mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
          rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
          home_path: /home/admin/oceanbase/test1
          data_dir: /data/test1
          redo_dir: /redo/test1
          zone: zone3
        z4:
          mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
          rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
          home_path: /home/admin/oceanbase/test2
          data_dir: /data/test2
          redo_dir: /redo/test2
          zone: zone1
        z5:
          mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
          rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
          home_path: /home/admin/oceanbase/test2
          data_dir: /data/test2
          redo_dir: /redo/test2
          zone: zone2
        z6:
          mysql_port: 3881 # External port for OceanBase Database. The default value is 2881.
          rpc_port: 3882 # Internal port for OceanBase Database. The default value is 2882.
          home_path: /home/admin/oceanbase/test2
          data_dir: /data/test2
          redo_dir: /redo/test2
          zone: zone3
      obproxy-ce:
        depends:
          - oceanbase-ce
        servers:
          - 10.10.10.1
        global:
          listen_port: 2888 # External port. The default value is 2883.
          prometheus_listen_port: 2884 # The Prometheus port. The default value is 2884.
          home_path: /home/admin/obproxy
          rs_list: 10.10.10.1:2881;10.10.10.2:2881;10.10.10.3:2881;10.10.10.4:2881;10.10.10.5:2881;10.10.10.6:2881
          enable_cluster_checkout: false
          cluster_name: obcluster
          obproxy_sys_password: ******** # obproxy sys user password, can be empty
          observer_sys_password: ******** # proxyro user pasword, consistent with oceanbase-ce's proxyro_password, can be empty
      ```

3. 再次启动原集群

   ```bash
   obd cluster start test1
   ```

4. 使用 root 用户重新登录集群的 sys 租户，添加新的进程

   其中，`server_ip` 表示待添加的节点的 IP 地址；`port_num` 表示节点的 RPC 端口号，默认为 `2882`。

   ```sql
   ALTER SYSTEM ADD SERVER 'server_ip:port_num' ZONE 'zone1';
   ALTER SYSTEM ADD SERVER 'server_ip:port_num' ZONE 'zone2';
   ALTER SYSTEM ADD SERVER 'server_ip:port_num' ZONE 'zone3';
   ```

5. 查看扩容结果

   ```sql
   select svr_ip,id,zone,status from __all_server;
   ```

   返回结果中可以看到每个 Zone 内都存在两个进程，则表示扩容成功。

6. 执行如下命令，添加 Unit 数量，为业务租户 ob_test1 扩容

   ```sql
   MySQL [oceanbase]> alter resource pool ob_test1_pool unit_num=2;
   Query OK, 0 rows affected (0.146 sec)
   ```

7. 参考如下步骤清除 OBD 中新集群的信息。

   清除新集群信息可以防止出现误操作，比如对新集群执行 destroy 命令导致新增节点的进程被终止。

   1. 查看配置路径

      ```bash
      obd cluster list
      ```

   2. 删除 OBD 中新集群的信息

      ```bash
      rm -rf .obd/cluster/test2
      ```
